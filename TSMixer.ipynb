{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e9f9fe6-d2e8-4a74-87e1-39c12d5079f3",
   "metadata": {},
   "source": [
    "# TSMixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85894f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-tsmixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523bff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def smape_loss(predicted, target):\n",
    "    \"\"\"\n",
    "    Compute Symmetric Mean Absolute Percentage Error (SMAPE) loss between predicted and target tensors.\n",
    "    Args:\n",
    "        predicted (torch.Tensor): Predicted values.\n",
    "        target (torch.Tensor): Target values.\n",
    "    Returns:\n",
    "        torch.Tensor: SMAPE loss.\n",
    "    \"\"\"\n",
    "    numerator = torch.abs(predicted - target)\n",
    "    denominator = (torch.abs(predicted) + torch.abs(target)) / 2.0\n",
    "    smape = torch.mean(numerator / denominator) * 100.0\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a55469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtsmixer import TSMixer\n",
    "import pandas as pd \n",
    "import sys\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import random\n",
    "\n",
    "\n",
    "def dataPreprocessor(fileName, dropScore, seq_len, pred_len, input_channels, output_channels):\n",
    "\n",
    "    ts = pd.read_csv(fileName)\n",
    "    # -------------- Data processing --------------\n",
    "    cumulative_clmsn = []\n",
    "    for clmn_name in ts:\n",
    "        if \"Cumulative\" in clmn_name:\n",
    "            cumulative_clmsn.append(clmn_name)\n",
    "        \n",
    "        if dropScore == True and \"score\" in clmn_name:\n",
    "            cumulative_clmsn.append(clmn_name)\n",
    "            \n",
    "    for entry in cumulative_clmsn:\n",
    "        ts.drop(columns=entry, inplace=True)\n",
    "    # -------------- Data processing --------------\n",
    "        \n",
    "    # Drop date\n",
    "    data = ts.select_dtypes(include=['float64', 'float32', 'float16', 'int64', 'int32', 'int16', 'int8', 'uint8'])\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "\n",
    "     # Model parameters\n",
    "    sequence_length = seq_len    \n",
    "    prediction_length = pred_len\n",
    "    print(input_channels)\n",
    "    print(len(data.columns) -1)\n",
    "    assert(input_channels == len(data.columns) - 1)\n",
    "\n",
    "    X_train = torch.empty(0, sequence_length, input_channels)\n",
    "    y_train = torch.empty(0, prediction_length, output_channels)\n",
    "\n",
    "    X_val = torch.empty(0, sequence_length, input_channels)\n",
    "    y_val = torch.empty(0, prediction_length, output_channels)\n",
    "\n",
    "    X_test = torch.empty(0, sequence_length, input_channels)\n",
    "    y_test = torch.empty(0, prediction_length, output_channels)\n",
    "\n",
    "    for start in range(1, len(data) - sequence_length - prediction_length + 1):\n",
    "        X_inst = torch.tensor(data.iloc[start:start + sequence_length, :-1].values, dtype=torch.float32)\n",
    "        y_inst = torch.tensor(data.iloc[start + sequence_length : start + sequence_length + prediction_length, -1:].values, dtype=torch.float32)    \n",
    "\n",
    "        coin_flip = random.randint(1, 100)\n",
    "\n",
    "        if coin_flip <= 80:\n",
    "            X_train = torch.cat((X_train, X_inst.unsqueeze(0)), dim = 0)\n",
    "            y_train = torch.cat((y_train, y_inst.unsqueeze(0)), dim = 0)\n",
    "        elif coin_flip <= 90:\n",
    "            X_val = torch.cat((X_val, X_inst.unsqueeze(0)), dim = 0)\n",
    "            y_val = torch.cat((y_val, y_inst.unsqueeze(0)), dim = 0)\n",
    "        else:\n",
    "            X_test = torch.cat((X_test, X_inst.unsqueeze(0)), dim = 0)\n",
    "            y_test = torch.cat((y_test, y_inst.unsqueeze(0)), dim = 0)\n",
    "\n",
    "    \n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_dataloader):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        # Extract a single batch from the dataset                   \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(X) \n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    return running_loss / len(train_dataloader.dataset)\n",
    "    \n",
    "\n",
    "def evaluate_model(model, criterion, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            outputs = model(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def findBestModelAndTest(X_train, y_train, X_val, y_val, X_test, y_test, seq_len, pred_len, input_channels, output_channels, batch_size, num_epochs):   \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle= False)\n",
    "\n",
    "    # Create the TSMixer model\n",
    "    model = TSMixer(seq_len, pred_len, input_channels, output_channels)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = smape_loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    # Train the model\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_model(model, criterion, optimizer, train_dataloader)\n",
    "        val_loss = evaluate_model(model, criterion, val_dataloader)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} (Model saved)')\n",
    "        else:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        # You can add early stopping here if val_loss does not decrease for a certain number of epochs\n",
    "        # You can also adjust learning rate based on validation loss\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)    \n",
    "\n",
    "    \n",
    "    test_loss = evaluate_model(model, criterion, test_dataloader)\n",
    "    print(f'Best Validation Loss: {best_val_loss:.4f}, Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropScore = 0\n",
    "seq_len = 21\n",
    "pred_len = 4\n",
    "input_channels = 12 - dropScore # HARDCODED\n",
    "output_channels = 1\n",
    "batch_size = 32\n",
    "\n",
    "allData = dataPreprocessor(\"covidDataWithSentiment.csv\", dropScore=dropScore, seq_len=seq_len, pred_len=pred_len, input_channels=input_channels, output_channels=output_channels)\n",
    "\n",
    "findBestModelAndTest(*allData, seq_len=21, pred_len=4, input_channels=input_channels, output_channels=output_channels, batch_size=batch_size, num_epochs=1400)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
