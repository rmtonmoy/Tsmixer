{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from transformers import pipeline\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isInFutureTenseOrPresentParticiple(sentence):\n",
    "    text = word_tokenize(sentence)\n",
    "    tagged = pos_tag(text)\n",
    "    for (word, tag) in tagged:\n",
    "        if(tag in [\"MD\", \"VB\", \"VBG\"]):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "isInFutureTenseOrPresentParticiple(\"Tomorrow I will go to school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(keyword, date, responseDict):\n",
    "    nude_keyword = re.sub('[^A-Za-z0-9]+', '', keyword).lower()\n",
    "    classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "\n",
    "    month = date.month\n",
    "    year = date.year\n",
    "    sleepTime = 10\n",
    "    key = (month, year)\n",
    "\n",
    "    if( key not in responseDict.keys()):\n",
    "        while(True):\n",
    "            url = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key=cOZRb3HZAYcI4njj6RGnDirpFWJy9twH\"\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if(response.status_code != 200):\n",
    "                time.sleep(sleepTime)       # To not get blocked\n",
    "                sleepTime = sleepTime + 1\n",
    "                print(f\"Updating sleeptime to : {sleepTime}\")\n",
    "            else:\n",
    "                responseDict.update({key: response})\n",
    "                print(f\"Saved a resposne on {date}\")\n",
    "                break\n",
    "    \n",
    "    all_data = responseDict[key].json()\n",
    "    articles = all_data[\"response\"][\"docs\"]\n",
    "\n",
    "    sum_score = 0\n",
    "    count = 0\n",
    "    on_date_article = 0\n",
    "\n",
    "    for entry in articles:\n",
    "        headline = entry[\"headline\"][\"main\"]\n",
    "        if(isInFutureTenseOrPresentParticiple(headline) == False):\n",
    "            continue\n",
    "\n",
    "        pub_datetime = datetime.datetime.strptime(entry[\"pub_date\"], '%Y-%m-%dT%H:%M:%S+%f')\n",
    "        pub_date = datetime.date(pub_datetime.year, pub_datetime.month, pub_datetime.day)\n",
    "\n",
    "        if(pub_date == date ):\n",
    "            nude_headline = re.sub('[^A-Za-z0-9]+', '', headline).lower()\n",
    "            on_date_article = on_date_article + 1\n",
    "\n",
    "            if(nude_keyword in nude_headline):\n",
    "                #print(f\"Relevant headline: {headline}\")\n",
    "                \n",
    "                sentiment_obj = classifier(headline)\n",
    "                sign = 1 \n",
    "                if(sentiment_obj[0][\"label\"] == \"NEGATIVE\"):\n",
    "                    sign = -1\n",
    "                sum_score = sum_score + (sign * sentiment_obj[0][\"score\"])\n",
    "                count = count + 1\n",
    "    \n",
    "    print(f\"#Article published on {date} is {on_date_article}\")\n",
    "    if(count == 0):\n",
    "        return 0\n",
    "    else: \n",
    "        #print(f\"Entry: {sum_score/count}\")\n",
    "        return sum_score / count\n",
    "    \n",
    "\n",
    "# Testing Code\n",
    "keyword = \"covid\"\n",
    "date = datetime.date(2021, 1, 27) # 2021-01-27\n",
    "dummyDict = dict()\n",
    "\n",
    "scr = get_sentiment(keyword, date, dummyDict)\n",
    "#date = date + datetime.timedelta(days = 1)\n",
    "#scr = get_sentiment(keyword, date, dummyDict)\n",
    "\n",
    "print(scr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both dates are inclusive\n",
    "def getSeries(keyword, startDate, endDate, file_name):\n",
    "    series = []\n",
    "    responseDict = dict()\n",
    "\n",
    "    while(startDate <= endDate):\n",
    "        scr = get_sentiment(keyword, startDate, responseDict)\n",
    "        series.append(scr)\n",
    "\n",
    "        file_append = open(file_name, \"a\")\n",
    "        file_append.write(f\"{startDate}, {scr}\\n\")\n",
    "        file_append.close()\n",
    "\n",
    "        startDate = startDate + datetime.timedelta(days=1)\n",
    "    \n",
    "    \n",
    "    return series \n",
    "\n",
    "file_name =  \"output.txt\"\n",
    "file_create = open(file_name, \"w\")\n",
    "file_create.write(\"date,score\\n\")\n",
    "file_create.close()\n",
    "\n",
    "# 2020-01-13\n",
    "# 2021-03-07\n",
    "startDate = datetime.date(2020, 1, 13)\n",
    "endDate = datetime.date(2021, 3, 7)\n",
    "sentiment_series = getSeries(\"covid\", startDate, endDate, file_name)\n",
    "\n",
    "#print(sentiment_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "print(sentiment_series)\n",
    "\n",
    "\n",
    "mini_srs = []\n",
    "gap = 30\n",
    "for i in range(0, len(sentiment_series), gap):\n",
    "    sum = 0\n",
    "    for j in range(i, i + gap):\n",
    "        if(j >= len(sentiment_series)):\n",
    "            break\n",
    "        sum += sentiment_series[j]\n",
    "    mini_srs.append(1 - sum/ gap)\n",
    "\n",
    "\n",
    "s = pd.Series(mini_srs)\n",
    "p = plt.plot(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
